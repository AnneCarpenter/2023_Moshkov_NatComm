{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.cluster.hierarchy as sch\n",
    "import random\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code serves as an example of filtering, it is obsolete after the data is filtered.  \\\n",
    "The filtered data is shared in this GitHub repository. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read assay files and remove assays listed as duplicates or private\n",
    "# The assay files below are NOT shared\n",
    "\n",
    "assay_train_file = '../data/assay_matrix_discrete_train_scaff_filt.csv'\n",
    "assay_test_file = '../data/assay_matrix_discrete_test_scaff.csv'\n",
    "assay_train_df = pd.read_csv(assay_train_file).fillna(-1)\n",
    "assay_test_df = pd.read_csv(assay_test_file).fillna(-1)\n",
    "assay_all_df = pd.concat([assay_train_df, assay_test_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assay_all_np = assay_all_df.to_numpy()[:, 1:].astype('int64')\n",
    "assay_all_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assay_all_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assay_all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load PAINS indicies\n",
    "pains_filtered_file = '../data/compound_analysis.npz'\n",
    "with open(pains_filtered_file, \"rb\") as data:\n",
    "    np_obj = np.load(data) \n",
    "    pains_overall = np_obj['pains_overall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove PAINS\n",
    "mask = np.zeros(16978, dtype=bool)\n",
    "mask[pains_overall] = True\n",
    "assays_np_nopains = assay_all_np[~mask]\n",
    "\n",
    "smiles_np = assay_all_df['smiles'].to_numpy()\n",
    "smiles_np_nopains = smiles_np[~mask]\n",
    "\n",
    "assays_nopains_df = pd.DataFrame(data = np.column_stack((smiles_np_nopains,assays_np_nopains)), columns = assay_all_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assays_nopains_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_col(df,col):\n",
    "    if (df[col] != 1).all():\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assays_without_hits = []\n",
    "for a in assays_nopains_df.columns[1:]:\n",
    "    if check_col(assays_nopains_df, a):\n",
    "        assays_without_hits.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove assays without hits\n",
    "assays_nopains_df.drop(columns=assays_without_hits, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assays_nopains_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider only hits\n",
    "assays_np_nopains = assays_nopains_df.to_numpy()[:,1:]\n",
    "assay_all_np_true = np.where(assays_np_nopains == 1,1,0)\n",
    "plt.gcf().set_size_inches(15, 15)\n",
    "sb.heatmap(assay_all_np_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assays_np_nopains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(.95)\n",
    "pca_res = pca.fit_transform(assay_all_np_true)\n",
    "a = pca_res[:,0:5]\n",
    "principalDf = pd.DataFrame(data = a, columns = ['PCA 1', 'PCA 2', 'PCA 3', 'PCA 4', 'PCA 5'])\n",
    "plt.figure(figsize=(12,12))\n",
    "color = sb.color_palette(\"hls\", 5)\n",
    "sb.scatterplot(data = principalDf, x=\"PCA 1\", y=\"PCA 2\", palette=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intersection matrix, diagonal values are zeros\n",
    "intersections = np.zeros((437,437))\n",
    "assay_activations = []\n",
    "for i in range(assay_all_np_true.shape[1]):\n",
    "    assay_activations.append(set(np.argwhere(assay_all_np_true[:,i]==1).flatten()))\n",
    "    \n",
    "for i in range(437):\n",
    "    for j in range(437):\n",
    "        if i != j:\n",
    "            intersections[i,j] = len(assay_activations[i].intersection(assay_activations[j]))\n",
    "            intersections[j,i] = len(assay_activations[i].intersection(assay_activations[j]))\n",
    "        \n",
    "        \n",
    "plt.gcf().set_size_inches(13, 13)    \n",
    "sb.heatmap(intersections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.clustermap(intersections, metric = 'cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intersection over union\n",
    "intersections_relative = np.zeros((437,437))\n",
    "assay_activations = []\n",
    "for i in range(assay_all_np_true.shape[1]):\n",
    "    assay_activations.append(set(np.argwhere(assay_all_np_true[:,i]==1).flatten()))\n",
    "    \n",
    "for i in range(437):\n",
    "    for j in range(437):\n",
    "        if len(assay_activations[i]) != 0 and len(assay_activations[j]) != 0:\n",
    "            intersections_relative[i,j] = len(assay_activations[i].intersection(assay_activations[j])) / len(assay_activations[i].union(assay_activations[j]))\n",
    "            intersections_relative[j,i] = len(assay_activations[i].intersection(assay_activations[j])) / len(assay_activations[i].union(assay_activations[j]))\n",
    "            if intersections_relative[i,j] > 0.7:\n",
    "                intersections_relative[i,j] = 1\n",
    "            else:\n",
    "                intersections_relative[i,j] = 0\n",
    "            \n",
    "            if intersections_relative[j,i] > 0.7:\n",
    "                intersections_relative[j,i] = 1\n",
    "            else:\n",
    "                intersections_relative[j,i] = 0\n",
    "        else:\n",
    "            intersections_relative[i,j] = 0\n",
    "            intersections_relative[j,i] = 0\n",
    "        \n",
    "        \n",
    "plt.gcf().set_size_inches(13, 13)    \n",
    "sb.heatmap(intersections_relative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clustering\n",
    "plt.gcf().set_size_inches(17, 30)  \n",
    "pl = sb.clustermap(intersections_relative, metric = 'cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersections_relative.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "d = sch.distance.pdist(intersections_relative, metric = 'cosine')\n",
    "L = sch.linkage(d, method='complete')\n",
    "clusters = sch.fcluster(L, 0.95*d.max(), 'distance')\n",
    "\n",
    "# clusters indicices correspond to incides of original df\n",
    "print(max(clusters))\n",
    "clusters_dict = {}\n",
    "for i,cluster in enumerate(clusters):\n",
    "    if cluster not in clusters_dict.keys():\n",
    "        clusters_dict[cluster] = []\n",
    "    \n",
    "    clusters_dict[cluster].append(i)\n",
    "\n",
    "#print(clusters_dict)\n",
    "keep = []\n",
    "for key in clusters_dict:\n",
    "    if len(clusters_dict[key]) == 1:\n",
    "        keep.append(clusters_dict[key][0])\n",
    "    elif len(clusters_dict[key]) > 1:\n",
    "        temp = random.sample(clusters_dict[key], int(len(clusters_dict[key])*0.3))\n",
    "        for t in temp:\n",
    "            keep.append(t)\n",
    "            \n",
    "print(len(keep))\n",
    "f = intersections_relative[keep,:]\n",
    "f = f[:,keep]\n",
    "print(f.shape)\n",
    "plt.gcf().set_size_inches(17, 30)  \n",
    "pl2 = sb.clustermap(f, metric = 'cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assays_to_keep = assays_nopains_df.columns[keep]\n",
    "assays_to_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assays_nopains_df_filtered_assays = assays_nopains_df[assays_to_keep]\n",
    "assays_nopains_df_filtered_assays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assays_nopains_df_filtered_assays_np = assays_nopains_df_filtered_assays.to_numpy()[:,1:]\n",
    "assays_nopains_df_filtered_assays_true = np.where(assays_nopains_df_filtered_assays_np == 1,1,0)\n",
    "sums = np.sum(assays_nopains_df_filtered_assays_true, axis=1)\n",
    "freq_compounds = [] \n",
    "for i in range(len(sums)):\n",
    "    if sums[i] > 30:\n",
    "        freq_compounds.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assays_nopains_df_filtered_assays.drop(freq_compounds, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assays_nopains_df_filtered_assays.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assays_nopains_df_filtered_assays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assays_without_hits2 = []\n",
    "for a in assays_nopains_df_filtered_assays.columns[1:]:\n",
    "    if check_col(assays_nopains_df_filtered_assays, a):\n",
    "        assays_without_hits2.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assays_nopains_df_filtered_assays_final = assays_nopains_df_filtered_assays.drop(columns=assays_without_hits2)\n",
    "assays_nopains_df_filtered_assays_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assays_nopains_df_filtered_assays_final.to_csv('../data/assay_matrix_discrete_270_assays.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assays_nopains_df_filtered_assays_final = pd.read_csv('../data/assay_matrix_discrete_270_assays.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assays_nopains_df_filtered_assays_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assays_np_nopains_final = assays_nopains_df_filtered_assays_final.to_numpy()[:,1:]\n",
    "assay_all_np_true_final = np.where(assays_np_nopains_final == 1,1,0)\n",
    "\n",
    "# intersection matrix, diagonal values are zeros\n",
    "# 270 is the number of assays obtained in the previous steps\n",
    "intersections_final = np.zeros((270,270))\n",
    "assay_activations_final = []\n",
    "for i in range(assay_all_np_true_final.shape[1]):\n",
    "    assay_activations_final.append(set(np.argwhere(assay_all_np_true_final[:,i]==1).flatten()))\n",
    "    \n",
    "for i in range(270):\n",
    "    for j in range(270):\n",
    "        if i != j:\n",
    "            intersections_final[i,j] = len(assay_activations_final[i].intersection(assay_activations_final[j]))\n",
    "            intersections_final[j,i] = len(assay_activations_final[i].intersection(assay_activations_final[j]))\n",
    "        \n",
    "        \n",
    "plt.gcf().set_size_inches(13, 13)    \n",
    "sb.heatmap(intersections_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assays_np_nopains_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intersection over union\n",
    "intersections_relative_final = np.zeros((270,270))\n",
    "assay_activations_final = []\n",
    "for i in range(assay_all_np_true_final.shape[1]):\n",
    "    assay_activations_final.append(set(np.argwhere(assay_all_np_true_final[:,i]==1).flatten()))\n",
    "    \n",
    "for i in range(270):\n",
    "    for j in range(270):\n",
    "        if len(assay_activations_final[i]) != 0 and len(assay_activations_final[j]) != 0:\n",
    "            intersections_relative_final[i,j] = len(assay_activations_final[i].intersection(assay_activations_final[j])) / len(assay_activations_final[i].union(assay_activations_final[j]))\n",
    "            intersections_relative_final[j,i] = len(assay_activations_final[i].intersection(assay_activations_final[j])) / len(assay_activations_final[i].union(assay_activations_final[j]))\n",
    "        else:\n",
    "            intersections_relative_final[i,j] = 0\n",
    "            intersections_relative_final[j,i] = 0\n",
    "        \n",
    "        \n",
    "plt.gcf().set_size_inches(13, 13)    \n",
    "pl2 = sb.clustermap(intersections_relative_final, metric = 'cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccc = []\n",
    "cccc = set(assays_nopains_df_filtered_assays.columns) - set(assays_without_hits2)\n",
    "for i in cccc:\n",
    "    ccc.append(list(assays_nopains_df_filtered_assays.columns).index(i))\n",
    "\n",
    "ff = f[:,ccc]\n",
    "ff = ff[ccc,:]\n",
    "plt.gcf().set_size_inches(17, 30)  \n",
    "pl2 = sb.clustermap(ff, metric = 'cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an IoU matrix with the order of element from clustering\n",
    "intersections_relative_reorder = np.zeros((270,270))\n",
    "for i in range(len(pl2.dendrogram_row.reordered_ind)):\n",
    "    for j in range(len(pl2.dendrogram_row.reordered_ind)):\n",
    "        intersections_relative_reorder[j,i] = intersections_relative_final[pl2.dendrogram_row.reordered_ind[j],pl2.dendrogram_row.reordered_ind[i]]\n",
    "        intersections_relative_reorder[i,j] = intersections_relative_final[pl2.dendrogram_row.reordered_ind[i],pl2.dendrogram_row.reordered_ind[j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.gcf().set_size_inches(13, 13) \n",
    "sb.heatmap(intersections_relative_reorder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assays_nopains_df_filtered_assays_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compounds16978 = assay_all_df['smiles'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#16 170 is the number of compounds left in the dataset\n",
    "compounds16170 = assays_nopains_df_filtered_assays_final['smiles'].to_list()\n",
    "indicies = []\n",
    "for i in range(len(compounds16170)):\n",
    "    indicies.append(compounds16978.index(compounds16170[i]))\n",
    "    \n",
    "print(len(indicies))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commented out as the file is already there\n",
    "# np.save('../data/compounds16978to16170.npy', indicies, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.gcf().set_size_inches(13, 13)\n",
    "sb.heatmap(intersections_relative_final)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "edf2f84eb977a12e0978a65dba77ae3558c42a07fd1fc4f86ffa70d5ed4d20be"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
