{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "# https://github.com/jingw2/size_constrained_clustering\n",
    "#from size_constrained_clustering import equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "assay_file = '../assay_data/assay_matrix_discrete_270_assays.csv'\n",
    "\n",
    "# Those feature and similarity files are available on Zenodo (dataset)\n",
    "ge_file = '../feature_data/ge.npz'\n",
    "ge_scaled_file = '../feature_data/ge_scaled.npz'\n",
    "mo_file = '../feature_data/mo.npz'\n",
    "cp_file = '../feature_data/cp.npz'\n",
    "mobc_file = '../feature_data/mobc.npz'\n",
    "\n",
    "similarity_fingerprints = '../misc/similarity_fingerprints.npz'\n",
    "\n",
    "with open(ge_file, \"rb\") as data:\n",
    "    ge_np = np.load(data)['features']\n",
    "        \n",
    "with open(mo_file, \"rb\") as data:\n",
    "    mo_np = np.load(data)['features']\n",
    "        \n",
    "with open(ge_scaled_file, \"rb\") as data:\n",
    "    ge_scaled_np = np.load(data)['features']\n",
    "        \n",
    "with open(cp_file, \"rb\") as data:\n",
    "    cp_np = np.load(data)['features']\n",
    "        \n",
    "with open(mobc_file, \"rb\") as data:\n",
    "    bc_mo_np = np.load(data)['features']\n",
    "\n",
    "with open(similarity_fingerprints, \"rb\") as data:\n",
    "    sim_fp = np.load(data)['features']\n",
    "\n",
    "gemobc_np = np.concatenate((ge_np, bc_mo_np), axis=1)\n",
    "\n",
    "with open('../misc/compounds16978to16170.npy', 'rb') as data:\n",
    "    compounds_final_indicies_from_16978 = np.load(data)\n",
    "\n",
    "mask=np.zeros(16978, dtype=bool)\n",
    "mask[compounds_final_indicies_from_16978] = True\n",
    "ge_np = ge_np[mask, :]\n",
    "mo_np = mo_np[mask, :]\n",
    "ge_scaled_np = ge_scaled_np[mask, :]\n",
    "cp_np = cp_np[mask, :]\n",
    "bc_mo_np = bc_mo_np[mask, :]\n",
    "gemobc_np = gemobc_np[mask, :]\n",
    "sim_fp = sim_fp[mask, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assay info is in csv files; we also store headers      \n",
    "assay_all_df = pd.read_csv(assay_file)\n",
    "assay_all_np = assay_all_df.to_numpy()\n",
    "assay_header = assay_all_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assay_all_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate sparsity of the assay matrix\n",
    "for_sparsity = assay_all_np[:, 1:].astype(np.float64)\n",
    "for_sparsity[for_sparsity == -1] = np.NaN\n",
    "np.isnan(for_sparsity).sum()/np.prod(for_sparsity.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate number of readouts in the assay matrix\n",
    "np.count_nonzero(~np.isnan(for_sparsity)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mean hit rate per assay\n",
    "row_hits = np.sum(for_sparsity == 1,axis=1)\n",
    "row_reads = np.sum(~np.isnan(for_sparsity),axis=1)\n",
    "np.mean(row_hits/row_reads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate readouts count per assay\n",
    "reads = np.sum(~np.isnan(for_sparsity))\n",
    "reads/270"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate hits count per assay\n",
    "hits = np.sum(for_sparsity == 1)\n",
    "hits/270"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#readout percentiles\n",
    "for_sparsity = assay_all_np[:, 1:].astype(np.float64)\n",
    "for_sparsity[for_sparsity == -1] = np.NaN\n",
    "b = np.sum(~np.isnan(for_sparsity),axis=0)\n",
    "np.percentile(b, [5,25,50,75,95])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create random splits (not cross validation)\n",
    "def train_test_split(cp_np_array, gemobc_np_array, bc_mo_np_array, ge_np_array, mo_np_array, ge_scaled_np_array, assay_all_np_array ):\n",
    "    indices_test = np.random.choice(cp_np_array.shape[0], int(cp_np_array.shape[0]*0.2), replace=False)\n",
    "    mask=np.zeros(cp_np_array.shape[0], dtype=bool)\n",
    "    mask[indices_test] = True\n",
    "    return indices_test, bc_mo_np_array[~mask, :],  bc_mo_np_array[mask, :], cp_np_array[~mask, :], cp_np_array[mask, :], \\\n",
    "            gemobc_np_array[~mask, :], gemobc_np_array[mask, :], ge_np_array[~mask, :], ge_np_array[mask, :], mo_np_array[~mask, :], \\\n",
    "            mo_np_array[mask, :], ge_scaled_np_array[~mask, :], ge_scaled_np_array[mask, :], assay_all_np_array[~mask, :], assay_all_np_array[mask, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_with_index_cv(indices_test, cp_np_array, gemobc_np_array, bc_mo_np_array, ge_np_array, mo_np_array, ge_scaled_np_array, assay_all_np_array ):\n",
    "    mask=np.zeros(cp_np_array.shape[0], dtype=bool)\n",
    "    mask[indices_test] = True\n",
    "    return bc_mo_np_array[~mask, :],  bc_mo_np_array[mask, :], cp_np_array[~mask, :], cp_np_array[mask, :], \\\n",
    "            gemobc_np_array[~mask, :], gemobc_np_array[mask, :], ge_np_array[~mask, :], ge_np_array[mask, :], mo_np_array[~mask, :], \\\n",
    "            mo_np_array[mask, :], ge_scaled_np_array[~mask, :], ge_scaled_np_array[mask, :], assay_all_np_array[~mask, :], assay_all_np_array[mask, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folders and files for random splits\n",
    "\n",
    "for i in range(0,10):\n",
    "    relative_path = '../data/random_{}'.format(i)\n",
    "    os.mkdir(relative_path)\n",
    "    os.chdir(relative_path)\n",
    "    indices_test, bc_mo_np_train, bc_mo_np_test, cp_np_train, cp_np_test, gemobc_np_train, gemobc_np_test, ge_np_train, \\\n",
    "        ge_np_test, mo_np_train, mo_np_test, ge_scaled_np_train, ge_scaled_np_test, assay_all_np_train, assay_all_np_test = \\\n",
    "        train_test_split(cp_np, gemobc_np, bc_mo_np, ge_np, mo_np, ge_scaled_np, assay_all_np)\n",
    "    \n",
    "    print(ge_np_train.shape, mo_np_train.shape, assay_all_np_train.shape)\n",
    "    \n",
    "    assay_train_npdf = np.concatenate((np.array(assay_header)[np.newaxis, :], assay_all_np_train), axis=0)\n",
    "    assay_test_npdf = np.concatenate((np.array(assay_header)[np.newaxis, :], assay_all_np_test), axis=0)\n",
    "    \n",
    "    assay_train_df = pd.DataFrame(data=assay_train_npdf[0:,0:])\n",
    "    assay_test_df = pd.DataFrame(data=assay_test_npdf[0:,0:])\n",
    "    \n",
    "    assay_train_df.to_csv('assay_matrix_discrete_train_scaff.csv', header=False, index=False)\n",
    "    assay_test_df.to_csv('assay_matrix_discrete_test_scaff.csv', header=False, index=False)\n",
    "    \n",
    "    #Commented out as those indices exist (can be found in the dataset files on Zenodo)\n",
    "    #np.savez('random_split_indicies_' + str(i) + '.npz', features=indices_test)\n",
    "    \n",
    "    np.savez('population_gemobc_train.npz', features=gemobc_np_train)\n",
    "    np.savez('population_gemobc_test.npz', features=gemobc_np_test)\n",
    "    np.savez('population_ge_train.npz', features=ge_np_train)\n",
    "    np.savez('population_ge_test.npz', features=ge_np_test)  \n",
    "    np.savez('population_mo_train.npz', features=mo_np_train)\n",
    "    np.savez('population_mo_test.npz', features=mo_np_test)\n",
    "    np.savez('population_mobc_train.npz', features=bc_mo_np_train)\n",
    "    np.savez('population_mobc_test.npz', features=bc_mo_np_test)  \n",
    "    np.savez('population_ge_scaled_train.npz', features=ge_scaled_np_train)\n",
    "    np.savez('population_ge_scaled_test.npz', features=ge_scaled_np_test)\n",
    "    np.savez('population_cp_train.npz', features=cp_np_train)\n",
    "    np.savez('population_cp_test.npz', features=cp_np_test)\n",
    "    os.chdir('../../analysis/')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate compound order for cross-validation\n",
    "all_indicies = np.arange(ge_np.shape[0])\n",
    "np.random.shuffle(all_indicies)\n",
    "print(all_indicies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the array, commented out as it is already exists\n",
    "#np.savez('./data/cross_validation_indicies_jan22.npz', features=all_indicies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folders and files with cross-validation splits\n",
    "\n",
    "with open('../splitting/cross_validation_indicies.npz', \"rb\") as data:\n",
    "    all_indicies = np.load(data) \n",
    "    all_indicies = all_indicies['features']\n",
    "\n",
    "for i in range(0,5):\n",
    "    relative_path = '../data/CV_cv{}'.format(i)\n",
    "    os.mkdir(relative_path)\n",
    "    os.chdir(relative_path)\n",
    "    if i < 4:\n",
    "        bc_mo_np_train, bc_mo_np_test, cp_np_train, cp_np_test, gemobc_np_train, gemobc_np_test, ge_np_train, \\\n",
    "        ge_np_test, mo_np_train, mo_np_test, ge_scaled_np_train, ge_scaled_np_test, assay_all_np_train, assay_all_np_test = \\\n",
    "        train_test_split_with_index_cv(all_indicies[i*3234:i*3234+3234], cp_np, gemobc_np, bc_mo_np, ge_np, mo_np, ge_scaled_np, assay_all_np)\n",
    "    else:\n",
    "        bc_mo_np_train, bc_mo_np_test, cp_np_train, cp_np_test, gemobc_np_train, gemobc_np_test, ge_np_train, \\\n",
    "        ge_np_test, mo_np_train, mo_np_test, ge_scaled_np_train, ge_scaled_np_test, assay_all_np_train, assay_all_np_test = \\\n",
    "        train_test_split_with_index_cv(all_indicies[i*3234:], cp_np, gemobc_np, bc_mo_np, ge_np, mo_np, ge_scaled_np, assay_all_np)\n",
    "    \n",
    "    print(gemobc_np_train.shape, bc_mo_np_train.shape, ge_np_train.shape, mo_np_train.shape, assay_all_np_train.shape, np.array(assay_header)[:, np.newaxis].shape)\n",
    "    print(gemobc_np_test.shape, bc_mo_np_test.shape, ge_np_test.shape, mo_np_test.shape, assay_all_np_test.shape, np.array(assay_header)[:, np.newaxis].shape)\n",
    "    \n",
    "    assay_train_npdf = np.concatenate((np.array(assay_header)[np.newaxis, :], assay_all_np_train), axis=0)\n",
    "    assay_test_npdf = np.concatenate((np.array(assay_header)[np.newaxis, :], assay_all_np_test), axis=0)\n",
    "    \n",
    "    assay_train_df = pd.DataFrame(data=assay_train_npdf[0:,0:])\n",
    "    assay_test_df = pd.DataFrame(data=assay_test_npdf[0:,0:])\n",
    "    \n",
    "    assay_train_df.to_csv('assay_matrix_discrete_train_scaff.csv', header=False, index=False)\n",
    "    assay_test_df.to_csv('assay_matrix_discrete_test_scaff.csv', header=False, index=False)\n",
    "    \n",
    "    np.savez('population_gemobc_train.npz', features=gemobc_np_train)\n",
    "    np.savez('population_gemobc_test.npz', features=gemobc_np_test)\n",
    "    np.savez('population_ge_train.npz', features=ge_np_train)\n",
    "    np.savez('population_ge_test.npz', features=ge_np_test)  \n",
    "    np.savez('population_mo_train.npz', features=mo_np_train)\n",
    "    np.savez('population_mo_test.npz', features=mo_np_test)\n",
    "    np.savez('population_mobc_train.npz', features=bc_mo_np_train)\n",
    "    np.savez('population_mobc_test.npz', features=bc_mo_np_test)  \n",
    "    np.savez('population_ge_scaled_train.npz', features=ge_scaled_np_train)\n",
    "    np.savez('population_ge_scaled_test.npz', features=ge_scaled_np_test)\n",
    "    np.savez('population_cp_train.npz', features=cp_np_train)\n",
    "    np.savez('population_cp_test.npz', features=cp_np_test)  \n",
    "    os.chdir('../../analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UMAP plot of morphology features\n",
    "reducer = umap.UMAP()\n",
    "embeddings = reducer.fit_transform(mo_np)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(x=embeddings[:,0], y=embeddings[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UMAP plot of batch-corrected morphology features\n",
    "reducer = umap.UMAP()\n",
    "embeddings = reducer.fit_transform(bc_mo_np)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(x=embeddings[:,0], y=embeddings[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UMAP plot of gene expression features\n",
    "reducer = umap.UMAP()\n",
    "embeddings = reducer.fit_transform(ge_np)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(x=embeddings[:,0], y=embeddings[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UMAP plot of classical chemical structures features\n",
    "reducer = umap.UMAP()\n",
    "embeddings = reducer.fit_transform(cp_np)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(x=embeddings[:,0], y=embeddings[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the path here to the clustering file; this method is for morphology and gene expression clusters index files\n",
    "def train_test_split_cluster(cp_np_array, gemobc_np_array, bc_mo_np_array, ge_np_array, mo_np_array, ge_scaled_np_array, assay_all_np_array, cluster):\n",
    "    with open('../splitting/MOBC_clusters_size_constrained.npz', \"rb\") as data:\n",
    "        clusters = np.load(data)\n",
    "        indices_test = np.argwhere(clusters['features']==cluster)\n",
    "        mask=np.zeros(cp_np_array.shape[0], dtype=bool)\n",
    "        mask[indices_test] = True\n",
    "        return bc_mo_np_array[~mask, :],  bc_mo_np_array[mask, :], cp_np_array[~mask, :], cp_np_array[mask, :], \\\n",
    "            gemobc_np_array[~mask, :], gemobc_np_array[mask, :], ge_np_array[~mask, :], ge_np_array[mask, :], mo_np_array[~mask, :], \\\n",
    "            mo_np_array[mask, :], ge_scaled_np_array[~mask, :], ge_scaled_np_array[mask, :], assay_all_np_array[~mask, :], assay_all_np_array[mask, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UMAP plots, then clustering of gene expression features, then makes an UMAP plots colored with clusters\n",
    "\n",
    "reducer = umap.UMAP()\n",
    "embeddings = reducer.fit_transform(ge_np)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(x=embeddings[:,0], y=embeddings[:,1])\n",
    "\n",
    "model = equal.SameSizeKMeansHeuristics(5)\n",
    "model.fit(ge_np)\n",
    "y_kmeans = model.labels_\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(embeddings[:, 0], embeddings[:, 1], c=y_kmeans, s=50, cmap='Pastel1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the array, commented out as it is already exists\n",
    "#np.savez('geneexp_clusters_size_constrainedF.npz', features=y_kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UMAP plots, then clustering of batch-corrected morphology features, then makes an UMAP plots colored with clusters\n",
    "reducer = umap.UMAP()\n",
    "embeddings = reducer.fit_transform(bc_mo_np)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(x=embeddings[:,0], y=embeddings[:,1])\n",
    "\n",
    "model = equal.SameSizeKMeansHeuristics(5)\n",
    "model.fit(bc_mo_np)\n",
    "y_kmeans = model.labels_\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(embeddings[:, 0], embeddings[:, 1], c=y_kmeans, s=50, cmap='Pastel1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.savez('MOBC_clusters_size_constrained.npz', features=y_kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folders and files for clustering based splits\n",
    "for i in range(0,5):\n",
    "    relative_path = '../data/MOBC_cv{}'.format(i)\n",
    "    os.mkdir(relative_path)\n",
    "    \n",
    "    bc_mo_np_train, bc_mo_np_test, cp_np_train, cp_np_test, gemobc_np_train, gemobc_np_test, ge_np_train, \\\n",
    "        ge_np_test, mo_np_train, mo_np_test, ge_scaled_np_train, ge_scaled_np_test, assay_all_np_train, assay_all_np_test = \\\n",
    "        train_test_split_cluster(cp_np, gemobc_np, bc_mo_np, ge_np, mo_np, ge_scaled_np, assay_all_np, i)\n",
    "\n",
    "    os.chdir(relative_path)\n",
    "    \n",
    "    print(bc_mo_np_train.shape, ge_np_train.shape, mo_np_train.shape, assay_all_np_train.shape, np.array(assay_header)[:, np.newaxis].shape)\n",
    "    print(bc_mo_np_test.shape, ge_np_test.shape, mo_np_test.shape, assay_all_np_test.shape, np.array(assay_header)[:, np.newaxis].shape)\n",
    "    \n",
    "    assay_train_npdf = np.concatenate((np.array(assay_header)[np.newaxis, :], assay_all_np_train), axis=0)\n",
    "    assay_test_npdf = np.concatenate((np.array(assay_header)[np.newaxis, :], assay_all_np_test), axis=0)\n",
    "    \n",
    "    assay_train_df = pd.DataFrame(data=assay_train_npdf[0:,0:])\n",
    "    assay_test_df = pd.DataFrame(data=assay_test_npdf[0:,0:])\n",
    "    \n",
    "    assay_train_df.to_csv('assay_matrix_discrete_train_scaff.csv', header=False, index=False)\n",
    "    assay_test_df.to_csv('assay_matrix_discrete_test_scaff.csv', header=False, index=False)\n",
    "    \n",
    "    np.savez('population_gemobc_train.npz', features=gemobc_np_train)\n",
    "    np.savez('population_gemobc_test.npz', features=gemobc_np_test)\n",
    "    np.savez('population_ge_train.npz', features=ge_np_train)\n",
    "    np.savez('population_ge_test.npz', features=ge_np_test)  \n",
    "    np.savez('population_mo_train.npz', features=mo_np_train)\n",
    "    np.savez('population_mo_test.npz', features=mo_np_test)\n",
    "    np.savez('population_mobc_train.npz', features=bc_mo_np_train)\n",
    "    np.savez('population_mobc_test.npz', features=bc_mo_np_test)  \n",
    "    np.savez('population_ge_scaled_train.npz', features=ge_scaled_np_train)\n",
    "    np.savez('population_ge_scaled_test.npz', features=ge_scaled_np_test)\n",
    "    np.savez('population_cp_train.npz', features=cp_np_train)\n",
    "    np.savez('population_cp_test.npz', features=cp_np_test)  \n",
    "    os.chdir('../../analysis')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../splitting/scaffold_based_split.npz', 'rb') as data:\n",
    "    chem_clusters = np.load(data, allow_pickle = True)\n",
    "    chem_clusters = chem_clusters['features']\n",
    "    \n",
    "for i in range(0,5):\n",
    "    relative_path = '../data/chemical_cv{}'.format(i)\n",
    "    os.mkdir(relative_path)\n",
    "    os.chdir(relative_path)\n",
    "\n",
    "    assay_all_np[assay_all_np==-1]=np.nan\n",
    "    bc_mo_np_train, bc_mo_np_test, cp_np_train, cp_np_test, gemobc_np_train, gemobc_np_test, ge_np_train, \\\n",
    "        ge_np_test, mo_np_train, mo_np_test, ge_scaled_np_train, ge_scaled_np_test, assay_all_np_train, assay_all_np_test = \\\n",
    "        train_test_split_with_index_cv(chem_clusters[i], cp_np, gemobc_np, bc_mo_np, ge_np, mo_np, ge_scaled_np, assay_all_np)\n",
    "    \n",
    "    print(gemobc_np_train.shape, bc_mo_np_train.shape, ge_np_train.shape, mo_np_train.shape, assay_all_np_train.shape, np.array(assay_header)[:, np.newaxis].shape)\n",
    "    print(gemobc_np_test.shape, bc_mo_np_test.shape, ge_np_test.shape, mo_np_test.shape, assay_all_np_test.shape, np.array(assay_header)[:, np.newaxis].shape)\n",
    "    \n",
    "    assay_train_npdf = np.concatenate((np.array(assay_header)[np.newaxis, :], assay_all_np_train), axis=0)\n",
    "    assay_test_npdf = np.concatenate((np.array(assay_header)[np.newaxis, :], assay_all_np_test), axis=0)\n",
    "    \n",
    "    assay_train_df = pd.DataFrame(data=assay_train_npdf[0:,0:])\n",
    "    assay_test_df = pd.DataFrame(data=assay_test_npdf[0:,0:])\n",
    "    \n",
    "    \n",
    "    assay_train_df.to_csv('assay_matrix_discrete_train_scaff.csv', header=False, index=False)\n",
    "    assay_test_df.to_csv('assay_matrix_discrete_test_scaff.csv', header=False, index=False)\n",
    "    \n",
    "    np.savez('population_gemobc_train.npz', features=gemobc_np_train)\n",
    "    np.savez('population_gemobc_test.npz', features=gemobc_np_test)\n",
    "    np.savez('population_ge_train.npz', features=ge_np_train)\n",
    "    np.savez('population_ge_test.npz', features=ge_np_test)  \n",
    "    np.savez('population_mo_train.npz', features=mo_np_train)\n",
    "    np.savez('population_mo_test.npz', features=mo_np_test)\n",
    "    np.savez('population_mobc_train.npz', features=bc_mo_np_train)\n",
    "    np.savez('population_mobc_test.npz', features=bc_mo_np_test)  \n",
    "    np.savez('population_ge_scaled_train.npz', features=ge_scaled_np_train)\n",
    "    np.savez('population_ge_scaled_test.npz', features=ge_scaled_np_test)\n",
    "    np.savez('population_cp_train.npz', features=cp_np_train)\n",
    "    np.savez('population_cp_test.npz', features=cp_np_test)  \n",
    "    os.chdir('../../analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot UMAP of classical features + plot UMAP of classical features colored by scaffold-based splits\n",
    "with open('../splitting/scaffold_based_split.npz', 'rb') as data:\n",
    "    colors = np.zeros((cp_np.shape[0]))\n",
    "    indices = np.load(data, allow_pickle=True)\n",
    "    indices = indices['features']\n",
    "    for i in range(5):\n",
    "        colors[indices[i]] = i\n",
    "\n",
    "reducer = umap.UMAP()\n",
    "embeddings = reducer.fit_transform(cp_np)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(x=embeddings[:,0], y=embeddings[:,1])\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(embeddings[:, 0], embeddings[:, 1], c=colors, s=50, cmap='Pastel1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "edf2f84eb977a12e0978a65dba77ae3558c42a07fd1fc4f86ffa70d5ed4d20be"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
